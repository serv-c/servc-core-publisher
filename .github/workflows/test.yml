name: 'Unit Tests'
on:
  pull_request:

jobs:
  unittest:
    runs-on: ubuntu-latest

    services:
      starrocks:
        image: starrocks/allin1-ubuntu
        ports:
          - 9030:9030

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - uses: actions/setup-python@v5
        with:
          python-version: 3.13

      - uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: temurin

      - uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.5.0'
          hadoop-version: '3'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Type check
        run: mypy main.py --check-untyped-defs

      - name: Run tests
        env:
          MYSQL_URL: mysql://root@{{ github.server_url != 'https://github.com' && 'starrocks' || '127.0.0.1' }}:9030
          CONF__DB__DBTYPE: sqlite
          CONF__DB__URL: sqlite:////tmp/test.db
          POD_IP: "127.0.0.1"
          CONF__LAKE__CATALOG_NAME: default
          CONF__LAKE__CATALOG_PROPERTIES__TYPE: sql
          CONF__LAKE__CATALOG_PROPERTIES__URI: sqlite:////tmp/lake.db
          CONF__LAKE__CATALOG_PROPERTIES__INIT_CATALOG_TABLES: true
          CONF__LAKE__CATALOG_PROPERTIES__WAREHOUSE: file:///tmp/warehouse
        run: |
          sudo mkdir -p $SPARK_HOME/conf
          sudo cat spark-defaults.conf >> $SPARK_HOME/conf/spark-defaults.conf
          sudo cat spark-defaults.conf >> /opt/hostedtoolcache/spark/3.5.0/x64/conf/spark-defaults.conf

          echo "Running tests"
          coverage run -m unittest tests/*.py
          coverage report -m --fail-under=70